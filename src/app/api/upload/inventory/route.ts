import { NextRequest, NextResponse } from 'next/server';
import { getServerSession } from 'next-auth';
import { authOptions } from '@/lib/auth';
import { validateFile, generateSecureFilename, scanFileContent } from '@/lib/security/file-upload';
import { sanitizeForExcel } from '@/lib/security/input-sanitization';
import { checkRateLimit, rateLimitConfigs } from '@/lib/security/rate-limiter';
import * as XLSX from 'xlsx';
import { z } from 'zod';

const MAX_FILE_SIZE = 10 * 1024 * 1024; // 10MB
const ALLOWED_TYPES = ['.xlsx', '.xls', '.csv'];

export async function POST(request: NextRequest) {
  try {
    // Rate limit file uploads
    const rateLimitResponse = await checkRateLimit(request, rateLimitConfigs.upload);
    if (rateLimitResponse) return rateLimitResponse;

    const session = await getServerSession(authOptions);
    if (!session?.user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const formData = await request.formData();
    const file = formData.get('file') as File;
    
    if (!file) {
      return NextResponse.json({ error: 'No file provided' }, { status: 400 });
    }

    // Validate file
    const buffer = Buffer.from(await file.arrayBuffer());
    const validation = await validateFile(buffer, file.name, {
      maxSizeMB: 10,
      allowedTypes: ALLOWED_TYPES,
      scanForMacros: true,
      checkMagicNumbers: true
    });

    if (!validation.valid) {
      return NextResponse.json(
        { error: validation.error },
        { status: 400 }
      );
    }

    // Additional content scanning
    const contentScan = await scanFileContent(buffer, file.name);
    if (!contentScan.safe) {
      return NextResponse.json(
        { error: 'File contains suspicious content', warnings: contentScan.warnings },
        { status: 400 }
      );
    }

    // Parse file based on type
    let data: any[] = [];
    const fileExt = file.name.split('.').pop()?.toLowerCase();

    if (fileExt === 'csv') {
      // Parse CSV
      const text = buffer.toString('utf-8');
      const lines = text.split('\n');
      const headers = lines[0].split(',').map(h => h.trim());
      
      for (let i = 1; i < lines.length; i++) {
        if (lines[i].trim()) {
          const values = lines[i].split(',');
          const row: any = {};
          headers.forEach((header, index) => {
            row[header] = sanitizeForExcel(values[index]?.trim() || '');
          });
          data.push(row);
        }
      }
    } else {
      // Parse Excel
      const workbook = XLSX.read(buffer, { type: 'buffer' });
      const sheetName = workbook.SheetNames[0];
      const sheet = workbook.Sheets[sheetName];
      
      // Convert to JSON with sanitization
      const rawData = XLSX.utils.sheet_to_json(sheet);
      data = rawData.map(row => {
        const sanitizedRow: any = {};
        for (const [key, value] of Object.entries(row as Record<string, unknown>)) {
          sanitizedRow[key] = sanitizeForExcel(String(value));
        }
        return sanitizedRow;
      });
    }

    // Validate data structure
    const rowSchema = z.object({
      SKU: z.string().min(1),
      Name: z.string().min(1),
      Quantity: z.number().positive().int(),
      Warehouse: z.string().min(1),
      BatchNumber: z.string().optional()
    });

    const validationErrors: any[] = [];
    const validRows: any[] = [];

    for (let i = 0; i < data.length; i++) {
      const result = rowSchema.safeParse(data[i]);
      if (result.success) {
        validRows.push(result.data);
      } else {
        validationErrors.push({
          row: i + 2, // +1 for header, +1 for 0-index
          errors: result.error.errors
        });
      }
    }

    if (validationErrors.length > 0) {
      return NextResponse.json({
        error: 'Validation errors in file',
        validRows: validRows.length,
        errors: validationErrors.slice(0, 10) // Limit error response
      }, { status: 400 });
    }

    // Process valid rows in batches to avoid memory issues
    const BATCH_SIZE = 100;
    const results = [];
    
    for (let i = 0; i < validRows.length; i += BATCH_SIZE) {
      const batch = validRows.slice(i, i + BATCH_SIZE);
      // Process batch...
      results.push({ batch: i / BATCH_SIZE + 1, processed: batch.length });
    }

    return NextResponse.json({
      success: true,
      totalRows: validRows.length,
      batches: results
    });

  } catch (error: any) {
    console.error('Upload error:', error);
    return NextResponse.json(
      { error: 'Failed to process file' },
      { status: 500 }
    );
  }
}